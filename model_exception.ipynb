{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6162e062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30e9239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52292d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conv --> batchnorm --> relu\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size, stride, padding, bias=False):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channel, out_channel, kernel_size, stride, padding, bias)\n",
    "        self.bn = nn.BatchNorm2d(out_channel)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.bn(self.conv(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8344aaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dept --> wisepoint\n",
    "class seperableConv(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size, stride, padding, bias=False):\n",
    "        super().__init__()\n",
    "        self.depthwise = nn.Conv2d(in_channel,\n",
    "                                   in_channel,\n",
    "                                   kernel_size, stride, padding,\n",
    "                                   groups=in_channel,\n",
    "                                   bias=bias)\n",
    "        self.pointwise = nn.Conv2d(in_channel, out_channel, 1, 1, 0, bias=bias) #kernel, stride, padding\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2321e5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#residuel block with 1x1 shortcut\n",
    "class EntryFlowBlock(nn.Module):\n",
    "  def __init__(self, in_channel, out_channel):\n",
    "    super().__init__() # Add this line\n",
    "    #shortcut path to make x in h(x) = f(x) + x (explain this later)\n",
    "    self.shortcut_conv = nn.Conv2d(in_channel, out_channel, 1, stride=2, bias=False)\n",
    "    self.shortcut_bn = nn.BatchNorm2d(out_channel)\n",
    "\n",
    "    #main path\n",
    "    self.sep_conv1 = seperableConv(in_channel, out_channel, 3, 1, 1, bias=False)\n",
    "    self.bn1 = nn.BatchNorm2d(out_channel) # This BatchNorm expects out_channel, which is 128\n",
    "    self.relu1 = nn.ReLU(inplace=True)\n",
    "\n",
    "    self.sep_conv2 = seperableConv(out_channel, out_channel, 3, 1, 1, bias=False)\n",
    "    self.bn2 = nn.BatchNorm2d(out_channel) # This BatchNorm expects out_channel, which is 128\n",
    "\n",
    "    self.pool1 = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    gx = self.shortcut_bn(self.shortcut_conv(x)) #g(x)\n",
    "\n",
    "    #mainpath\n",
    "    fx = self.bn1(self.sep_conv1(x))\n",
    "    fx = self.relu1(fx)\n",
    "    fx = self.bn2(self.sep_conv2(fx))\n",
    "    fx = self.pool1(fx)\n",
    "\n",
    "    return fx + gx #h(x) = f(x) + g(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ed650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#residule from the middle floW\n",
    "class MiddleFlowBlock(nn.Module):\n",
    "  def __init__(self, channels=728):\n",
    "    super().__init__()\n",
    "\n",
    "    self.relu = nn.ReLU()\n",
    "    self.sep_conv1 = seperableConv(channels, channels, 3, 1, 1, bias=False)\n",
    "    self.bn1 = nn.BatchNorm2d(channels)\n",
    "\n",
    "    self.sep_conv2 = seperableConv(channels, channels, 3, 1, 1, bias=False)\n",
    "    self.bn2 = nn.BatchNorm2d(channels)\n",
    "\n",
    "    self.sep_conv3 = seperableConv(channels, channels, 3, 1, 1, bias=False)\n",
    "    self.bn3 = nn.BatchNorm2d(channels)\n",
    "\n",
    "  def forward(self, x):\n",
    "    shortcut = x\n",
    "\n",
    "    fx = self.relu(x)\n",
    "    fx = self.bn1(self.sep_conv1(fx))\n",
    "    fx = self.relu(fx)\n",
    "    fx = self.bn2(self.sep_conv2(fx))\n",
    "    fx = self.relu(fx)\n",
    "    fx = self.bn3(self.sep_conv3(fx))\n",
    "\n",
    "    return fx + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d797ee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExitFlowBlock(nn.Module):\n",
    "  def __init__(self, in_channel=728, out_channel=1028):\n",
    "    super().__init__()\n",
    "    #shortcut path g(x)\n",
    "    self.shortcut_conv = nn.Conv2d(in_channel, out_channel, 1, stride=2, bias=False)\n",
    "    self.shortcut_bn = nn.BatchNorm2d(out_channel)\n",
    "\n",
    "    #f(x) path\n",
    "    self.relu = nn.ReLU()\n",
    "    self.sep_conv1 = seperableConv(in_channel, out_channel, 3, 1, 1, bias=False)\n",
    "    self.bn1 = nn.BatchNorm2d(out_channel)\n",
    "\n",
    "    self.sep_conv2 = seperableConv(out_channel, out_channel, 3, 1, 1, bias=False)\n",
    "    self.bn2 = nn.BatchNorm2d(out_channel)\n",
    "\n",
    "    self.pool = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    gx = self.shortcut_bn(self.shortcut_conv(x))\n",
    "\n",
    "    fx = self.relu(x)\n",
    "    fx = self.bn1(self.sep_conv1(fx))\n",
    "    fx = self.relu(fx)\n",
    "    fx = self.bn2(self.sep_conv2(fx))\n",
    "    fx = self.pool(fx)\n",
    "\n",
    "    return fx + gx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a2a977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sepconv -> bn -> relu\n",
    "class sepconvRelu(nn.Module):\n",
    "  def __init__(self, in_channel, out_channel):\n",
    "    super().__init__()\n",
    "    self.sep_conv = seperableConv(in_channel, out_channel, 3, 1, 1, bias=False)\n",
    "    self.bn = nn.BatchNorm2d(out_channel)\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.relu(self.bn(self.sep_conv(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1292d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_xception(nn.Module):\n",
    "  def __init__(self, output_size, lr=1e-3):\n",
    "    super().__init__()\n",
    "\n",
    "    self.entryflow = nn.Sequential(\n",
    "        ConvBlock(3, 32, 3, 2, 0),\n",
    "        ConvBlock(32, 64, 3, 1, 1),\n",
    "\n",
    "\n",
    "        EntryFlowBlock(64, 128),\n",
    "        EntryFlowBlock(128, 256),\n",
    "        EntryFlowBlock(256, 728)\n",
    "    )\n",
    "\n",
    "    middle_blocks = []\n",
    "    for _ in range(8):\n",
    "      middle_blocks.append(MiddleFlowBlock(channels=728))\n",
    "\n",
    "    self.middleflow = nn.Sequential(*middle_blocks)\n",
    "\n",
    "    self.exitflow = nn.Sequential(\n",
    "        ExitFlowBlock(728, 1024),\n",
    "        sepconvRelu(1024, 1536),\n",
    "        sepconvRelu(1536, 2048)\n",
    "    )\n",
    "\n",
    "    self.glob_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "    self.fc = nn.Linear(2048, output_size)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.entryflow(x)\n",
    "    x = self.middleflow(x)\n",
    "    x = self.exitflow(x)\n",
    "    x = self.glob_avg_pool(x)\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = self.fc(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3e8c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "zip_folder_path = './handsign.zip'\n",
    "\n",
    "local_extraction_path = './handsign_local'\n",
    "\n",
    "if os.path.exists(local_extraction_path) is False:\n",
    "  os.makedirs(local_extraction_path, exist_ok=True)\n",
    "\n",
    "  with zipfile.ZipFile(zip_folder_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(local_extraction_path)\n",
    "\n",
    "  print(f\"Items of {zip_folder_path} to {local_extraction_path}\")\n",
    "else:\n",
    "  print(\"Already unzip\")\n",
    "\n",
    "import shutil\n",
    "\n",
    "items = os.listdir(local_extraction_path)\n",
    "for i in items:\n",
    "  if(i == '__MACOSX'):\n",
    "    shutil.rmtree(os.path.join(local_extraction_path, i))\n",
    "\n",
    "items = os.listdir(local_extraction_path) # Refresh\n",
    "print(items)\n",
    "\n",
    "class_labels = ['thumbs-up', 'okay', 'peace', 'palm-up', 'palm-down']\n",
    "\n",
    "def extract_images(PATH: Path):\n",
    "    data = {}\n",
    "    for dir in PATH.iterdir():\n",
    "        if not dir.is_dir():\n",
    "            continue\n",
    "\n",
    "        print('Found Directory: ', dir)\n",
    "        print('Extracting...')\n",
    "        data[dir.name] = {}\n",
    "        dir_dict = data[dir.name]\n",
    "\n",
    "        img_path = dir / 'images'\n",
    "        labels_path = dir / 'labels'\n",
    "\n",
    "        if not img_path.is_dir() or not labels_path.is_dir():\n",
    "            print(f\"  Skipping {dir.name}: 'images' or 'labels' folder missing.\")\n",
    "            continue\n",
    "\n",
    "        label_files = list(labels_path.glob('*.txt'))\n",
    "        if not label_files:\n",
    "            print(f\"  No .txt label files found in {labels_path}\")\n",
    "            continue\n",
    "\n",
    "        log = None\n",
    "        for i, label_file in enumerate(label_files):\n",
    "            file_stem = label_file.stem\n",
    "\n",
    "            # Find the matching image (jpg, png, etc.)\n",
    "            image_pth = next(img_path.glob(f'{file_stem}.*'), None)\n",
    "\n",
    "            if image_pth is None: # If no matching image, skip\n",
    "                continue\n",
    "\n",
    "            try: # If label file is corrupt, skip\n",
    "                with open(label_file, 'r') as f:\n",
    "                    cls = int(f.read().split()[0])\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            if cls not in dir_dict.keys():\n",
    "                dir_dict[cls] = []\n",
    "            dir_dict[cls].append(image_pth)\n",
    "\n",
    "            log = f'Building Data, Found : {i + 1} / {len(label_files)}'\n",
    "            print(log, end='\\r')\n",
    "\n",
    "        if log:\n",
    "            print(log) # Print final count\n",
    "    return data\n",
    "\n",
    "class HandSignsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom dataset for a hand signs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, transforms):\n",
    "        \"\"\"\n",
    "\n",
    "        initializes the dataset from a dictionary in the format\n",
    "\n",
    "        {\n",
    "            class_0 : list_image_path\n",
    "            ...\n",
    "            class_N : list_image_path\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "        self.data = data\n",
    "        self.transforms = transforms\n",
    "\n",
    "        self.flat_data = [(img, cls) for cls, imgs in data.items() for img in imgs]\n",
    "\n",
    "    def class_count(self):\n",
    "        \"\"\"\n",
    "        returns the count of data for each class\n",
    "        \"\"\"\n",
    "\n",
    "        for cls, data in self.data.items():\n",
    "\n",
    "            print(f'class {cls} : {len(data)}')\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        returns the\n",
    "        \"\"\"\n",
    "        return len(self.flat_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        indexes self.flat_data, returns a transformed image and the class as a tensor\n",
    "        \"\"\"\n",
    "        image_pth, cls = self.flat_data[index]\n",
    "        image = Image.open(image_pth)\n",
    "        transformed_image = self.transforms(image)\n",
    "\n",
    "        return  transformed_image, torch.tensor(cls)\n",
    "    \n",
    "base_path = Path('./handsign_local')\n",
    "data = extract_images(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c955b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "  def __init__(self, model, train_loader, val_loader, criterion, optimizer, num_epochs=20, scheduler=None):\n",
    "\n",
    "    #training device variables group\n",
    "    self.device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "\n",
    "    self.model = model.to(self.device)\n",
    "\n",
    "    #data loader variables group\n",
    "    self.train_loader = train_loader\n",
    "    self.val_loader = val_loader\n",
    "\n",
    "    #training variables group\n",
    "    self.criterion = criterion\n",
    "    self.optimizer = optimizer\n",
    "    self.num_epochs = num_epochs\n",
    "\n",
    "    self.scheduler = scheduler\n",
    "\n",
    "    #variabels for tracking and plotting\n",
    "    self.train_losses = []\n",
    "    self.val_losses = []\n",
    "    self.train_accuracies = []\n",
    "    self.val_accuracies = []\n",
    "\n",
    "    # TensorBoard writer\n",
    "    self.writer = SummaryWriter()\n",
    "\n",
    "  \"\"\"\n",
    "  This iterates through each epochs to train the model\n",
    "  it tracks train/val loss and accuracy\n",
    "  This methods also write log for tensor board for result visulization and comparation\n",
    "  \"\"\"\n",
    "  def fit(self):\n",
    "    for epoch in range(self.num_epochs):\n",
    "      train_loss, train_accuracy = self.train()\n",
    "      val_loss, val_accuracy = self.evaluate()\n",
    "\n",
    "      if self.scheduler:\n",
    "                self.scheduler.step()\n",
    "\n",
    "      # Store loss and accuracy values\n",
    "      self.train_losses.append(train_loss)\n",
    "      self.train_accuracies.append(train_accuracy)\n",
    "      self.val_losses.append(val_loss)\n",
    "      self.val_accuracies.append(val_accuracy)\n",
    "\n",
    "      # Log metrics to TensorBoard\n",
    "      self.writer.add_scalar('Loss/Train', train_loss, epoch)\n",
    "      self.writer.add_scalar('Loss/Validation', val_loss, epoch)\n",
    "      self.writer.add_scalar('Accuracy/Train', train_accuracy, epoch)\n",
    "      self.writer.add_scalar('Accuracy/Validation', val_accuracy, epoch)\n",
    "      print(f'Epoch [{epoch+1}/{self.num_epochs}], '\n",
    "            f' Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%,'\n",
    "            f' Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
    "    self.writer.close() # Close the writer after training is complete\n",
    "\n",
    "  \"\"\"\n",
    "  This class mode the model on training mode, and uses running loss, correct predicting, and total samples\n",
    "  to track the loss and accuracy of the model\n",
    "\n",
    "  The main thing of this method is the gradient calculation\n",
    "  This basically adjusting the (w,b), so for example, y = aw+b. We are finding the best set of (w,b)\n",
    "  Then, next time a is enterd, the y will be calculated.\n",
    "\n",
    "  before doing something, we first cleaning the preivous gradient and calculate the new ones\n",
    "  \"\"\"\n",
    "  def train(self):\n",
    "    run_loss = 0.0\n",
    "    correct_pred = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    self.model.train()  # Set model to training mode\n",
    "\n",
    "    for images, labels in self.train_loader:\n",
    "      images, labels = images.to(self.device), labels.to(self.device)\n",
    "\n",
    "      self.optimizer.zero_grad()\n",
    "      outputs = self.model(images)\n",
    "      loss = self.criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      self.optimizer.step()\n",
    "\n",
    "      # Track loss and accuracy\n",
    "      run_loss += loss.item()\n",
    "      _, predicted = torch.max(outputs, 1)\n",
    "      correct_pred += (predicted == labels).sum().item()\n",
    "      total_samples += labels.size(0)\n",
    "\n",
    "    # Calculate training loss and accuracy\n",
    "    train_loss = run_loss / len(self.train_loader)\n",
    "    train_accuracy = correct_pred / total_samples * 100\n",
    "\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "  \"\"\"\n",
    "  This method is used for evaludating the model,\n",
    "  the main role of this one is\n",
    "  after training, we will to evaluate it in order to fine-tune it\n",
    "  Therefore, in this method, there is no gradient calculation\n",
    "  \"\"\"\n",
    "  @torch.no_grad()\n",
    "  def evaluate(self):\n",
    "    val_loss = 0.0\n",
    "    correct_pred = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    self.model.eval()  # Set model to evaluation mode\n",
    "    for images, labels in self.val_loader:\n",
    "      images, labels = images.to(self.device), labels.to(self.device)\n",
    "\n",
    "      # Forward pass\n",
    "      outputs = self.model(images)\n",
    "      loss = self.criterion(outputs, labels)\n",
    "      val_loss += loss.item()\n",
    "\n",
    "      # Track accuracy\n",
    "      _, predicted = torch.max(outputs, 1)\n",
    "      correct_pred += (predicted == labels).sum().item()\n",
    "      total_samples += labels.size(0)\n",
    "\n",
    "    # Calculate validation loss and accuracy\n",
    "    val_loss = val_loss / len(self.val_loader)\n",
    "    val_accuracy = correct_pred / total_samples * 100\n",
    "\n",
    "    return val_loss, val_accuracy\n",
    "\n",
    "  def save_model(self, path):\n",
    "    print(f'Saving {self.model} to {path}')\n",
    "    with open(path, 'wb') as f:\n",
    "      pickle.dump(self.model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d232145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "IMG_size = 299\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    # transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "testVal_transform = transforms.Compose([\n",
    "    transforms.transforms.Resize(IMG_size),\n",
    "    transforms.CenterCrop(IMG_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "train_set = HandSignsDataset(data['train'], train_transform)\n",
    "test_set = HandSignsDataset(data['test'], testVal_transform)\n",
    "val_set = HandSignsDataset(data['valid'], testVal_transform)\n",
    "\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_dataloader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_dataloader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "print(\"DataLoader objects created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b86a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = 5\n",
    "\n",
    "xception = my_xception(output_dim, lr=1e-4)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    xception.cuda()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "trainable_params = filter(lambda p: p.requires_grad, xception.parameters())\n",
    "optimizer = optim.Adam(trainable_params, lr=1e-4)\n",
    "\n",
    "xception_trainer = Trainer(xception, train_dataloader, val_dataloader, criterion, optimizer, num_epochs=15)\n",
    "xception_trainer.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
